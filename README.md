# MPD Value Iteration Algorithm
little project done late in the night for fun. it still needs some revision but it should work - well, at least it does with the study cases we met during lectures.

# Purpose of the project
The purpose of the project is to build a program that performs the value iteration to determine an approximation of the optimal values necessary for the optimal policy.
This is probably the most bothersome phase of the Markov Decision Process, and after doing it a couple of times I ain't gonna do it anymore, so here is where this program comes in handy.

# Features to be added and planned revisions (soon, possibly)
- re-organize the whole project
- provide a better solution for graph creation
- implment input from keyboard (well it's not that hard but it looks so inefficient for me to input the values manually)
- implement input from file (well since keyboard buuu, then file good, right?)
- add a documentation with nice comments


# Commit 08/10
things happened, I moved a few directories and made an exceptional mess, so there you go, a new repository so that now the project uses fancy maven as a fancy archetype.
